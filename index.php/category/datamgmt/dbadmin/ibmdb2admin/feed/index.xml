<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>IBM DB2 Admin &#8211; LessthanDot</title>
	<atom:link href="/index.php/category/datamgmt/dbadmin/ibmdb2admin/feed/" rel="self" type="application/rss+xml" />
	<link>/</link>
	<description>A Technical Community for IT Professionals</description>
	<lastBuildDate>Sat, 09 Mar 2019 12:50:36 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.6.1</generator>
	<item>
		<title>Is being a DBA still sexy?</title>
		<link>/index.php/datamgmt/dbadmin/is-being-a-dba-still/</link>
		<comments>/index.php/datamgmt/dbadmin/is-being-a-dba-still/#comments</comments>
		<pubDate>Wed, 14 Nov 2012 11:46:00 +0000</pubDate>
		<dc:creator><![CDATA[Jes Borland]]></dc:creator>
				<category><![CDATA[Database Administration]]></category>
		<category><![CDATA[IBM DB2 Admin]]></category>
		<category><![CDATA[Microsoft SQL Server Admin]]></category>
		<category><![CDATA[MySQL Admin]]></category>
		<category><![CDATA[Oracle Admin]]></category>

		<guid isPermaLink="false">/index.php/2012/11/is-being-a-dba-still/</guid>
		<description><![CDATA[I hear more and more emphasis on two things: big data and business intelligence. Companies are investing more and more money in both. Knowing this, are you, a DBA, thinking your job is threatened?]]></description>
				<content:encoded><![CDATA[<p>I hear more and more emphasis on two things: big data and business intelligence. Companies are investing more and more money in both. Conferences are providing more tracks on those topics. Books that focus on these topics seem to be everywhere. They were the focus of last week’s keynotes at PASS Summit. Yes, there is a lot of data out there. Yes, mining the data the business has collected for analysis, insights, and trends is what keeps the business moving forward. These topics are sexy. They&#8217;re attractive. People want to see them, and spend time with them.</p>
<p>Knowing this, are you, a DBA, thinking your job is threatened? Are you worried that you will get phased out with time, or relegated to a dark basement office, next to the server room? Does data seem unattractive, and, let&#8217;s face it, unsexy? Do you fear becoming a <a href="http://www.imdb.com/character/ch0001900/">Milton</a>?</p>
<p> </p>
<p style="text-align: center;"><img src="http://cdn.ebaumsworld.com/2012/03/82378978/stapler.jpg" alt="" /></p>
<p><em>Don’t worry.</em> As long as there is data, there will be a need for a data steward; for someone to protect it and keep it accessible. As we’ve moved toward more computerized cars, have mechanics disappeared? No! They have had to change their approach and learn more about the computers they work with, but they are still changing oil and replacing timing belts.</p>
<p>If you want to keep enjoying your job, and be attracted to it, now is the time to start learning new features and facets of SQL Server. This will keep you fresh, because you will learn new things. It will keep you marketable, because companies are going to need these skills going forward. It will show your current or potential employers that you are willing to stay current, which is a valuable skill.</p>
<p>What are some ways to keep database administration sexy?</p>
<h3>Managing VLDBs (Very Large Databases)</h3>
<p>As the amount of data we store continues to grow, you will need to know how to manage larger volumes. Consider new backup strategies. Investigate things like backup compression, striping across multiple files, and multiple filegroups. Want a lesson? Ask Bob Pusateri (<a href="http://www.bobpusateri.com/">blog</a> | <a href="https://twitter.com/SQLBob">twitter</a>) about his backup story.</p>
<p>There is more to administration than backups, of course. Consider other tasks like restoring backups, CHECKDB, and index maintenance. How are you going to handle each of these things? There are many new (or less well-known) strategies, such as CHECK FILEGROUP or custom index maintenance scripts that you could implement.</p>
<p> </p>
<p style="text-align: center;"><img src="http://2.bp.blogspot.com/-SuWyCTDJnJU/T17QTJys85I/AAAAAAAAGRw/-roZPgMTkH8/s1600/very+large+tea+mug.jpg" alt="" /></p>
<p style="text-align: center;"><em>Your database is like my coffee cup: LARGE</em></p>
<h3>Indexing</h3>
<p>There is a new world of data out there – XML, spatial, and flat out large amounts of data. This data needs indexing, too. Do you understand how spatial data is stored, and how indexing can help it? (If you don’t, be sure to ask Ted (<a href="/index.php?disp=authdir&amp;author=68">blog</a> | <a href="https://twitter.com/onpnt">twitter</a>) for his explanation.) Do you know how to retrieve XML data and what to index on it? What are strategies to help retrieve large amounts of data, such as filtered indexes and columnstore indexes with xVelocity technology? xVelocity is sexy. It even sounds cool. All of this and more will be more prevalent in the coming years.</p>
<h3>Storage</h3>
<p>As the volume of data grows, a physical SQL Server instance can outgrow attached, dedicated disk. We now work in environments with terabytes of data in SANs, which are shared between multiple servers, which are used by multiple virtual machines and hosts. Understanding the architecture of these systems, and how all the pieces communicate and work together, will be a vital part of the DBA job going forward.</p>
<p style="text-align: center;"><em><img src="http://www.oppictures.com/singleimages/400/54477.JPG" alt="" /><br /></em></p>
<p style="text-align: center;"><em>How many of these would it take to store your data?</em></p>
<h3>Look Forward</h3>
<p>By realizing that the world of data is changing and committing to change with it, you are positioning yourself to have a successful future.   Start researching the future of data. Think about what you are interested in learning about the future. Begin studying and applying what you’re learning. You&#8217;re going to be attracted to your job again. It&#8217;s going to be sexy to be a DBA for years to come!</p>
]]></content:encoded>
			<wfw:commentRss>/index.php/datamgmt/dbadmin/is-being-a-dba-still/feed/</wfw:commentRss>
		<slash:comments>5</slash:comments>
		</item>
		<item>
		<title>Using schemas to maintain order as a DBA</title>
		<link>/index.php/datamgmt/datadesign/grouping-dba-junk/</link>
		<comments>/index.php/datamgmt/datadesign/grouping-dba-junk/#comments</comments>
		<pubDate>Fri, 26 Feb 2010 13:28:54 +0000</pubDate>
		<dc:creator><![CDATA[Ted Krueger (onpnt)]]></dc:creator>
				<category><![CDATA[Data Modelling and Design]]></category>
		<category><![CDATA[Database Administration]]></category>
		<category><![CDATA[Database Programming]]></category>
		<category><![CDATA[IBM DB2 Admin]]></category>
		<category><![CDATA[Microsoft SQL Server]]></category>
		<category><![CDATA[Microsoft SQL Server Admin]]></category>
		<category><![CDATA[MySQL Admin]]></category>
		<category><![CDATA[Oracle Admin]]></category>
		<category><![CDATA[dba]]></category>
		<category><![CDATA[schema]]></category>
		<category><![CDATA[sql server]]></category>

		<guid isPermaLink="false">/index.php/2010/02/grouping-dba-junk/</guid>
		<description><![CDATA[Chaos or order? Managing objects in large and small installations of SQL Server can be a job in itself at times. In particular, for the DBA, objects we create on the instances we manage more often than not are found littered over the user and system databases. These objects more often are found in the [&#8230;]]]></description>
				<content:encoded><![CDATA[<p></p>
<h2>Chaos or order?</h2>
<p>
Managing objects in large and small installations of SQL Server can be a job in itself at times. In particular, for the DBA, objects we create on the instances we manage more often than not are found littered over the user and system databases. These objects more often are found in the master database in SQL Server. Really, why not put them there? We are the “masters” over the database server right? SSMS has this quality to it that when we connect to it, we get the master database glaring us in the face by default just like a booby.  So of course that means we create our objects there. Right? </p>
<div class="image_block"><img src="/wp-content/uploads/blogs/DataMgmt/booby.gif" alt="" title="" width="460" height="504" /></p>
<h3>Who&#8217;s really the booby?</h3>
</div>
<p>
After years managing the databases, we may find ourselves feeling just like that booby when it takes minutes, hours and sometimes even failing to find the scripts we previously created to maintain our database servers.
</p>
<p>
Maintaining order as a DBA starts with our own messes. That’s a pretty direct statement we can really dive into. SQL Server has for many versions given us the ability to manage our messes by grouping them into meaningful areas called schemas. Many times people set schemas aside and only think of them as a security method but they are much more. They take the booby out of us!
</p>
<p>
In my own installations each instance contains a DBA database and everything I do as a DBA or Developer resides in there. To learn more about that first step in maintaining order check out, &#8220;<a href="/index.php/DataMgmt/DBAdmin/MSSQLServerAdmin/instance-design-where-to-do-your-work-as">Instance design; Where to do your work as a DBA and DB Developer</a>&#8220;.</p>
<p>We can go much farther than that knowing schemas are available to us by grouping objects specific to other databases we maintain.
</p>
<p>
Let’s say we have two databases on an instance named, ERP and WMS. In our DBA database we can create schemas to match the databases such as WMS_OBJ and ERP_OBJ. Now when we create procedures, function, views and so on we can put them into the schema that represents the database they refer to.</p>
<pre>CREATE PROCEDURE WMS_OBJ.GRABAWIDGET
AS
SELECT WIDGETS FROM WMS.WIDGET_TABLE</pre>
<p>Without much thought we can quickly find all our objects </p>
<pre>SELECT * FROM INFORMATION_SCHEMA.ROUTINES 
WHERE SPECIFIC_SCHEMA = 'WMS_OBJ'</pre>
<p></p>
<p>Quickly we see the grouping and maintenance benefits of doing this but it doesn’t stop there. Once these objects are grouped in schemas, we can manage all of them as a single entity. They can be scripted to DR sites quickly, replicated, moved and a really cool point, we can authorize users to gain access to these schemas. If new team members come into your group you can quickly give them the schema rights they need to get started while maintaining the other schemas and security levels. We can transfer objects from schema to schema as well making migrations quicker and easier.
</p>
<h2>Take aways…</h2>
<p>
In all, schemas make us better DBAs by allowing us quicker responses to situations by having order on our database servers. Security is stronger and better managed as well. Upon connecting to SSMS, first check to see if you are in the master database.  Get in the habit of working outside the master database for greater control and to leave a smaller footprint on the system side of SQL Server. Take a few minutes to look at the objects used daily, monthly or even yearly and see if they can be grouped into schemas. After the initial work of creating the schemas and moving objects to them, I think order just may be achieved.</p>
]]></content:encoded>
			<wfw:commentRss>/index.php/datamgmt/datadesign/grouping-dba-junk/feed/</wfw:commentRss>
		<slash:comments>3</slash:comments>
		</item>
		<item>
		<title>SQL Saturday in Chicago &#8211; Schedule is up!</title>
		<link>/index.php/datamgmt/datadesign/sql-saturday-in-chicago-schedule-is-up/</link>
		<comments>/index.php/datamgmt/datadesign/sql-saturday-in-chicago-schedule-is-up/#comments</comments>
		<pubDate>Thu, 11 Feb 2010 23:51:46 +0000</pubDate>
		<dc:creator><![CDATA[Ted Krueger (onpnt)]]></dc:creator>
				<category><![CDATA[Data Modelling and Design]]></category>
		<category><![CDATA[Database Administration]]></category>
		<category><![CDATA[Database Programming]]></category>
		<category><![CDATA[IBM DB2]]></category>
		<category><![CDATA[IBM DB2 Admin]]></category>
		<category><![CDATA[Microsoft SQL Server]]></category>
		<category><![CDATA[Microsoft SQL Server Admin]]></category>
		<category><![CDATA[MySQL]]></category>
		<category><![CDATA[MySQL Admin]]></category>
		<category><![CDATA[Oracle]]></category>
		<category><![CDATA[Oracle Admin]]></category>

		<guid isPermaLink="false">/index.php/2010/02/sql-saturday-in-chicago-schedule-is-up/</guid>
		<description><![CDATA[Scheduled! The SQL Saturday in Chicago team has been working pretty hard lately on the schedule. It was difficult to complete due to all of the sessions being so good. I was close to trying a two day event so we could get all ~70 submissions up the weekend of April 17th. You can now [&#8230;]]]></description>
				<content:encoded><![CDATA[<div class="image_block"><img src="/wp-content/uploads/blogs/DataMgmt/sqlsat2.gif" alt="" title="" width="265" height="121" /></div>
<p><span class="MT_under"><br />
<h2>Scheduled!</h2>
<p></span></p>
<p>
The SQL Saturday in Chicago team has been working pretty hard lately on the schedule.  It was difficult to complete due to all of the sessions being so good.  I was close to trying a two day event so we could get all ~70 submissions up the weekend of April 17th.   </p>
<p>You can now see the schedule up on the SQL Saturday site <a href="http://www.sqlsaturday.com/31/schedule.aspx">here</a>
</p>
<p>
Of course we had to pick what the location we are using could handle and I think the team did an excellent job.  At last count we only have around 100 open spots left until we reach capacity so move quickly and get your registration in before the seats are taken.
</p>
<p><span class="MT_under"><br />
<h2>Questions not covered?</h2>
<p></span></p>
<p>
We will be holding an, “Ask the experts” session after the regular schedule also.  This means basically you bring your questions to all of us and we’ll do our best to answer them then and there.  If we can’t, we’ll twitter it and get an answer in a few minutes using #sqlhelp <img src="https://s.w.org/images/core/emoji/2/72x72/1f609.png" alt="😉" class="wp-smiley" style="height: 1em; max-height: 1em;" />  Jorge already tested that theory at the last SSUG he was attending.
</p>
<p><span class="MT_under"><br />
<h2>Sponsorship is how we do this</h2>
<p></span></p>
<p>
I would also like to take this time to thank each and every sponsor that is helping us with this event.  Combined with the speakers, volunteers and sponsorship, this event would not be possible.  Remember, this is a completely free event thanks to our most generous sponsors.</p>
<p>You can see the impressive list of sponsors <a href="http://www.sqlsaturday.com/31/sponsors.aspx">here</a>
</p>
<p>
Each company has been great to work with and I’m looking forward to learning more about some of the products they have introduced me to while discussing SQL with them.<br />
We still have a few sponsors to get up on the site so check back regularly to see who will be active in the event as sponsors.  </p>
<p>The event is also being held in a hotel so if you are traveling, getting to your room and the sessions is easier than you may think.  Details on the location can be found <a href="http://www.sqlsaturday.com/31/location.aspx">here</a>
</p>
<p></p>
<h1>I hope to see you all there!</h1>
]]></content:encoded>
			<wfw:commentRss>/index.php/datamgmt/datadesign/sql-saturday-in-chicago-schedule-is-up/feed/</wfw:commentRss>
		<slash:comments>5</slash:comments>
		</item>
		<item>
		<title>Introducing SQL Server to Oracle</title>
		<link>/index.php/datamgmt/datadesign/introducing-sql-server-to-oracle/</link>
		<comments>/index.php/datamgmt/datadesign/introducing-sql-server-to-oracle/#comments</comments>
		<pubDate>Fri, 11 Dec 2009 13:37:21 +0000</pubDate>
		<dc:creator><![CDATA[Ted Krueger (onpnt)]]></dc:creator>
				<category><![CDATA[Data Modelling and Design]]></category>
		<category><![CDATA[Database Administration]]></category>
		<category><![CDATA[Database Programming]]></category>
		<category><![CDATA[IBM DB2]]></category>
		<category><![CDATA[IBM DB2 Admin]]></category>
		<category><![CDATA[Microsoft SQL Server]]></category>
		<category><![CDATA[Microsoft SQL Server Admin]]></category>
		<category><![CDATA[MySQL]]></category>
		<category><![CDATA[MySQL Admin]]></category>
		<category><![CDATA[Oracle]]></category>
		<category><![CDATA[Oracle Admin]]></category>

		<guid isPermaLink="false">/index.php/2009/12/introducing-sql-server-to-oracle/</guid>
		<description><![CDATA[Over the last few weeks I have been working on the task of bringing an Oracle database into my SQL Server landscape. The basic process that needs to be accomplished is to get this Oracle database pumped into the existing SQL Server structure primarily to address the reporting aspect and requirements. The software that utilizes [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>Over the last few weeks I have been working on the task of bringing an Oracle database into my SQL Server landscape.  The basic process that needs to be accomplished is to get this Oracle database pumped into the existing SQL Server structure primarily to address the reporting aspect and requirements.  The software that utilizes the Oracle database could easily sit in their own little world without much need for us to go outside that shell but given my completely SSRS reporting structure, there is a need to build off the new data store for the users taking into account the completely native SQL Server backend.</p>
<p>Oracle can easily bring itself into SSRS as a data source.  In fact I highly recommend only doing that if you find yourself with this task.  The company I currently work with however, require that the data be backed up, available in all sources and backed up again.  To resolve the businesses needs I chose to bring the entire Oracle database into a SQL Server database nightly so the data was readily available and easily accessed by the skills of my group.  In my experience as a SQL Server professional, when Oracle is introduced into a SQL Server environment, the last thing you want to do to your developers and Jr. DBAs is install the Oracle client on all their machines and then throw SQL*Plus at them.  There is a reason that it’s hard to find cross dressing Oracle/SQL Server Experts.  They mix like UNIX and Windows OS.</p>
<p>The major key that will adjust the process of how you obtain a complete extract from Oracle to SQL Server is the size of data and the network structure.  One thing you should think about prior to starting the actual setup of this type is what data do you really need?  In the case when there is a set based data result you can export in a 24 hour period by date, you can look at this process as a type of wannabe warehouse ETL process.  Use SQL Server as your holding tank in which you retain the critical data that is required to recover and supply the business with the data.  SQL Server Integrated Services is a tool that can quickly get you up and running on the type of export I’m outlining above.   With SSIS you can work with the Oracle design to bridge the data into a SQL Server design.  This gives you an upper hand over writing queries that may not be efficient in T-SQL to extract data for reporting by means of doing the conversion to the SQL Server design at export/import stages.</p>
<p>Now that I’ve laid down the plan, I want to make one hardened statement.  “Never install the Oracle client on a production database server that holds other databases that are critical to the company”.</p>
<p>You may be asking why I say that without much room for the maybe situations.  Here are the facts.  You are probably reading this because you are a SQL Server shop and have little to no Oracle experience or an Oracle DBA on hand.  In my experience, the Oracle client is not an easy task for SQL Server DBAs to plug in and get going.  I have done this 4 times in my career and still have a hard time with it.  There are basic steps involved to get Oracle working from remote servers.  Install the client, setup TNSNAMES and a few other minor requirements just to get a functioning SQL*Plus session.  On each installation those steps never went the same and were never direct for me.  The reasoning behind this is, we as SQL Server DBAs are not Oracle infrastructure experts.  Spending a day reading up on how the client and Oracle instance work together on Windows (possibly to UX) is not efficient to call anyone an expert on any process.  Don’t approach this task as if you are.  It has failure and hardships written all over it.  </p>
<p>If you have the resources and budget available, create a job server installation that can assist in making the implementation of the Oracle instance onto your SQL Server instances easier to manage and troubleshoot.  Job servers are something I push for in all environments for SQL Server.  There is performance factors that come to mind when putting major job tasks on production database server that have the task of serving data to the business.  It is an easy resolution to a growing or already large integration services group to move them off to an instance that is designated and configured to handle the different needs of SSIS and what you are doing with it.</p>
<p>So even with my poor diagramming abilities, you can see the safety barrier between the two different systems.  </p>
<div class="image_block"><img src="/wp-content/uploads/blogs/DataMgmt//job_diagram.gif" alt="" title="" width="540" height="480" /></div>
<p>
Don’t get me wrong on everything I’ve written either.  I am not an Oracle hatter.  Yes, I have chosen the SQL Server DBA path because it’s just that much better (:P).  I have worked on DB2, Oracle and SQL Server.  All have their strengths and all have weaknesses.  </p>
<p>When the time comes for you to think about making them all work together, I hope this short blog of a possible mix will help you get the gears going.  It’s critical in the process of integrating different database servers into your environment to ensure they do not affect the abilities of them working optimally.</p>
]]></content:encoded>
			<wfw:commentRss>/index.php/datamgmt/datadesign/introducing-sql-server-to-oracle/feed/</wfw:commentRss>
		<slash:comments>8</slash:comments>
		</item>
		<item>
		<title>Beginning stages of a DR plan for SQL Server</title>
		<link>/index.php/datamgmt/datadesign/beginning-stages-of-a-dr-plan-for-sql-se/</link>
		<comments>/index.php/datamgmt/datadesign/beginning-stages-of-a-dr-plan-for-sql-se/#comments</comments>
		<pubDate>Fri, 13 Nov 2009 14:06:44 +0000</pubDate>
		<dc:creator><![CDATA[Ted Krueger (onpnt)]]></dc:creator>
				<category><![CDATA[Data Modelling and Design]]></category>
		<category><![CDATA[Database Administration]]></category>
		<category><![CDATA[IBM DB2 Admin]]></category>
		<category><![CDATA[Microsoft SQL Server]]></category>
		<category><![CDATA[Microsoft SQL Server Admin]]></category>

		<guid isPermaLink="false">/index.php/2009/11/beginning-stages-of-a-dr-plan-for-sql-se/</guid>
		<description><![CDATA[I’ve found that many companies find out what true Disaster Recovery is only in the presence of a true disaster. Obviously this is not a very optimal time to start thinking about what could have done to keep the money flowing through the veins of the company. In the near future I will be writing [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>I’ve found that many companies find out what true Disaster Recovery is only in the presence of a true disaster.  Obviously this is not a very optimal time to start thinking about what could have done to keep the money flowing through the veins of the company.
</p>
<p>In the near future I will be writing a series based around DR.  The series will be mostly geared towards your SQL Server instances and some tricks and tips to make recovery quicker for you.  I&#8217;ll also be touching on some important factors that are not commonly part of planning.  Some of those are</p>
<ul>
<li>DBA object recovery. Includes the objects you use to do your job</li>
<li>The decision to failover</li>
<li>Business buy-in</li>
<li>Business Impacts</li>
<li>Business failover </li>
<li>Having the business ready for a disaster</li>
</ul>
<p>However before we get into these details we need to cover a more important topic, the DBA.</p>
<h2>The DBA &#8211; The Most Critical DR Ingredient</h2>
<p>DBAs are the most critical part of a disaster recovery plan. As DBA&#8217;s, we are entrusted to make sure the data is secure on not only the primary sites but also the recovery sites.  There are many ways in which we can be successful in that goal and many are already native to SQL Server.  Log shipping, replication, snapshots, backup and restore and even scripting abilities are all part of native capabilities you can use to secure an offsite solution.  Some of the these features are limited to Enterprise edition but, even with Standard edition, we have enough options to cover our bases. The DBAs knowledge and analytical skills are the foundation that the DR plan is built upon, so we will look first at some of the built-in features and how they can help build out that foundation.</p>
<h2>What type of disaster is it?</h2>
<p>When I start putting together a disaster and recovery plan for SQL Server, I look at disasters in different levels of recovery.  For each of these levels, I put together my methods and strategies for recovering from them.  Looking from a recovery point can uncover problems in strategies that may not be seen until an actual failover.</p>
<h2>The levels of recovery</h2>
<ul>
<li>Audit Recovery</li>
<li>Low level object recovery</li>
<li>High level object recovery</li>
<li>Point of failure recovery</li>
<li>Complete recovery</li>
</ul>
<p></p>
<div class="image_block"><img src="/wp-content/uploads/blogs/DataMgmt/line.gif" alt="" title="" width="100%" /></div>
<p></p>
<div class="image_block"><img src="/wp-content/uploads/blogs/DataMgmt/easylanding.gif" alt="" title="" width="142" height="149" /></div>
<h2 style="text-align:center"><i><b>Audit recovery</b></i></h2>
<p>These recovery points are any requests that require analysis on corruption, financials or even data changes captured over time or are non-critical in nature. This is a slow paced recovery.  Corruption would be the fine line between Audit and Object recovery. If the corruption involves any type of situation where a company process is in the stop mode, you have to make the managing decision to move the recovery level to the next phase. If these disasters are not stopping the business flow, then backups can come into play to recover. Typically, in an Audit recovery level disaster, you have the time and resources for restoring data from backups because they do not affect the flow of money like most disasters do. </p>
<div class="image_block"><img src="/wp-content/uploads/blogs/DataMgmt/ducttape.gif" alt="" title="" width="136" height="136" /></div>
<h2 style="text-align:center"><i><b>Low level object recovery</b></i></h2>
<p>Low level object recovery consists of any object in the database that the company needs in order to successfully complete a transaction. A transaction is defined in many ways. Typically with any business, it means from the customer initial contact to sale of services or widgets. Objects can be non-critical tables, views, procedures, reports, database level security and other programmable objects. Good methods of recovery in this category are snapshots, test restores, UAT systems, third party log reading tools for rolling back transactions and object level recovery. In some cases, when the time is available, a restore from a backup stored locally can be achieved.  </p>
<p><span class="MT_red">Tip: Typically more important tables are backed up through file groups on files in the database which are recovered quicker than a full restore in that sense.</span><br />
Low level object recovery can be a rapid recovery point most of the time.  This level usually starts and ends with the DBA.  Simple methods such as table backups and object versioning or scripting can prevent loss and promote quick recovery points before the disaster ever becomes critical. </p>
<div class="image_block"><img src="/wp-content/uploads/blogs/DataMgmt/kissit.gif" alt="" title="" width="136" height="136" /></div>
<h2 style="text-align:center"><i><b>High level object recovery</b></i></h2>
<p>Critical objects, mirrors, replication settings, instance level security and service critical objects like endpoints and message queues are a few in this level. Third party object level recovery is again in the list of tools to recover these types of objects but you will find yourself going to configuration documentation and scripts much more here. Yes, scripts saved as a backup can be a life saver in the event of a disaster.<br />
High level can fall into disabling disasters or exposure disaster. Disabling disasters explain themselves. The business flow is completely stopped at this point. Exposure disasters are of the same importance but less of an impact to the actual flow of data. Mirroring is a major object that falls into the exposure listing. If you lose a mirror, business still runs but at a cost of being exposed to a much more critical disaster. </p>
<div class="image_block"><img src="/wp-content/uploads/blogs/DataMgmt/cablesinhand.gif" alt="" title="" width="165" height="111" /></div>
<h2 style="text-align:center"><i><b>Point of failure recovery</b></i></h2>
<p>This is a very high-level object recovery plan. This includes entire databases, instances, replication subscriptions and even entire facilities &#8211; but does not specifically stop the flow of money through the company. This recovery may simply mean you fail portions of your systems to your offsite DR location. This is a Disaster Recovery level but also can be blurred into HA (High Availability). The defining line between the two is that, in the case of a high recovery event, HA is typically part of the disaster and immediate loss.  Essentially, this becomes a recovery point in your DR plans when HA strategies fail or are not in place at all. The largest object defined in this level is an entire manufacturing location or hub in the company’s infrastructure. One prime example is a case I went through last year when a hurricane hit our Texas facility.  DR strategy&#8217;s part in the high level recovery went into effect to recover from the complete loss of communication with the facility. In my experience, this can be the most time-consuming recovery point if you don’t think about it before it happens. </p>
<div class="image_block"><img src="/wp-content/uploads/blogs/DataMgmt/rip.gif" alt="" title="" width="134" height="132" /></div>
<h2 style="text-align:center"><i><b>Complete recovery</b></i></h2>
<p>Last and most terrifying is the heart pounding moments we as DBAs live for. The database has become an ex-database, it is no more. I test these types of failures by pulling power plugs on main switches.  I still believe you are not fully experienced until you have been involved in one or two of these.  At the same time, I wish them upon no one with a weak heart.  Trust me, it doesn’t go as smooth as you think it will or your DR tests may have gone. Fire, lightning frying the entire state of Illinois, your servers under water or your mother-in-law in town; there are a lot of forces that can cause a complete failure.  At this time, you and your group make the hard decision to fail over completely to the offsite location. That really is a big decision and should never be taken lightly.  Many variables come into play when making the call to do this.  When it does happen, you’ll probably have documented and tested how each should be brought up at your DR site. There isn’t much to say about this stage other than you need a complete replica of the systems that are needed to run the business.  Remember, DR sites don’t only consist of databases.  This also means you need to keep patch levels of applications, security and everything down to SQL Agent job changes up to date on the DR site. It is good practice in planning DR to assume you could lose everything and never get it back. So even knowing things like reporting services may not be critical, it’s always a good idea to have a way to get all that back by using DR methods to create replicas.</p>
<h2><i><b>Wrap up…</b></i></h2>
<p>It is important to remember that all of these levels affect business and that means the business must be involved in most of them. Setting up log shipping to a server offsite is not nearly enough for a successful DR plan. The business needs to know how to start using that source and also has to buy into the effectiveness of its ability to run the business processes that make money. </p>
]]></content:encoded>
			<wfw:commentRss>/index.php/datamgmt/datadesign/beginning-stages-of-a-dr-plan-for-sql-se/feed/</wfw:commentRss>
		<slash:comments>7</slash:comments>
		</item>
		<item>
		<title>Death by a thousand tools</title>
		<link>/index.php/datamgmt/dbadmin/death-by-a-thousand-tools/</link>
		<comments>/index.php/datamgmt/dbadmin/death-by-a-thousand-tools/#comments</comments>
		<pubDate>Wed, 19 Aug 2009 11:09:48 +0000</pubDate>
		<dc:creator><![CDATA[Ted Krueger (onpnt)]]></dc:creator>
				<category><![CDATA[Database Administration]]></category>
		<category><![CDATA[IBM DB2 Admin]]></category>
		<category><![CDATA[Microsoft SQL Server Admin]]></category>
		<category><![CDATA[MySQL Admin]]></category>
		<category><![CDATA[Oracle Admin]]></category>

		<guid isPermaLink="false">/index.php/2009/08/death-by-a-thousand-tools/</guid>
		<description><![CDATA[One thing these days that there is not a shortage of is tools to monitor, tune and process our database servers. We have all the big wigs providing you with dozens of packaged utilities that ensure everything you have worked hard for stays where it is and meeting your hard 99.999999% availability goals. So is [&#8230;]]]></description>
				<content:encoded><![CDATA[<p>One thing these days that there is not a shortage of is tools to monitor, tune and process our database servers.  We have all the big wigs providing you with dozens of packaged utilities that ensure everything you have worked hard for stays where it is and meeting your hard 99.999999% availability goals.  So is that a good thing?  Obviously using these tools are a good thing and they make DBAs look that much better with real-time proactive performance tuning and preventative actions before issues are even issues.  The one thing I think it bad with all these bells and whistles is the concept of, “you can never have too many of them”.   Remember that <a href="http://www.youtube.com/watch?v=F63tYLhiqZ8&amp;feature=related">IBM commercial</a> with the thousands of old dust collecting servers?  </p>
<div class="image_block"><img src="/wp-content/uploads/blogs/DataMgmt//ibm_com.gif" alt="" title="" width="477" height="237" /></div>
<p>Even knowing I’m not a blade fan and the mainframe commercial still makes me laugh, that marketing plan was spot on not only with servers but all aspects to the environment.  </p>
<p>When you decide your database server landscape has become a true animal in itself and the work that you put into simple monitoring efforts daily is overwhelming, you will start your search for the all saving  tool that you can open every morning and simply look for green or red lights.  I’ve tried to pass to others that these tools are a must and the cost is minimal to the results.  There is a catch though.  Let’s think about the 5 hour energy drink prone, coffee crazed DBA that goes hog wild on downloading tools to do all sorts of things.  They grab a monitor, a disk analyzer, an OS monitor, network monitor, fragmentation monitor, native tools add-ins up the *** and basically a tool per though that comes to mind.  Now let’s look at the morning routine.  They click 300 icons on their desktop to open all of these tools.  They see green lights here and red lights there and blue and yellow spots in their vision because they’ve come to a point the tools that were so cool and freed all that time up for them to actually get some work done have become the actual work itself.  Then they spend the next 5 hours maintaining the tools themselves.  </p>
<p>It’s obvious and all experienced professionals will know that even too much of a good thing can make your life harder.  Most people have come to know that I love automation. It’s my bread and butter in the way I meet any new landscape or new task.  I enjoy the fact any given instance the company I work for and has entrusted me with keeping a heart beat will tell me the millisecond it has issues with any aspect to the ability of serving the customer with the data it holds so dear to its heart.  In order to do that and get yourself to a point you can successfully say that will happen, you have to take preparation and planning into the automation itself.  This goes with the third parties you come to love so dearly.  When you decide it is time the company needs to invest in monitoring tools and others that automate administration or simply make it a more real-time proactive setting, you have to do just that in taking time to plan it out.  The thing you need to avoid is getting to the point in which the tools that are supposed to be helping you do not become a job in themselves for maintenance.   That means, before you down 30 different tools, put great thought into which one can achieve all the tasks that the 29 in reality perform so you cover your bases with minimal effort in the tool itself.  </p>
<p>Now there is no one tool to rule them all.  You’ll have a few that you call your friend and there is always some maintenance that goes along with having those tools in your bed with you.  My hope in reading this is that you’ll think about it before you download a dozen things that in reality all do the same thing but because that one has a pretty picture or this one can blast so many emails you end up on the blacklist, you actually stop to decide which of those is better or will really help you do your job.  The last thing you want to fall into is having a landscape of tools and not database servers.   So when you plan your purchase put effort forth in planning what you have in your landscape already and what you really want to get out of a “master” tool.  Ever landscape is similar but very different.  An <a href="http://www.idera.com/Products/SQL-Server/SQL-diagnostic-manager/">Idera SQL Diagnostic Manager</a> may be perfect complimented by Red Gates, <a href="http://www.red-gate.com/products/sql_bundles/SQL_Comparison_Bundle.htm">SQL Compare bundle</a>.  At the same token <a href="http://www.quest.com/spotlight-on-sql-server-enterprise/">Quest Spotlight</a> with some <a href="http://www.quest.com/litespeed-for-sql-server/">Litespeed</a> and <a href="http://www.quest.com/capacity-manager-for-sql-server/">Capacity Manager</a> may give you the upper hand.  Those then possibly all combined or mismatched then give you minimal needs for maintaining them or expanding them.  One thing that is a good idea to do is listen to others on what they are using but never make a decision just because some MVP is using this or that.  It doesn’t mean it fits in your personality and manner of maintaining things along with the configurations of the landscape you have created.</p>
<p>Some of the things that come to mind to think about when deciding which tools fit in the environment the best are</p>
<ul>
<li>Does it require system object on a repository or all servers</li>
<li>Does it require features that typically I would cringe on enabling</li>
<li>Does it integrate seamlessly into my personal network infrastructure?  </li>
<li>Is it portable</li>
<li>How much maintenance will it in reality add to my job</li>
<li>Most of all, will it affect my instances negatively</li>
<li>Cost weighed against the amount of individual installations</li>
<li>Reporting for yourself and upper management</li>
<li>Can it make me better and not dumber?   This means if the tool itself goes down, what effort is it to manually do the tasks or have another do them</li>
<li>How robust is the notifications and alerting abilities.</li>
<li>Reviews of the product</li>
</ul>
<p>These rolled off just while writing this.  You’ve probably gotten the point that it’s not just a matter of downloading a trial version of something along with becoming its slave in doing exactly what it needs you to do in order to get it to work simply because it gives you cool dashboard pictures.  That doesn’t make it right for your instances.  It really is as complex implementation and requires planning as does implementing any software package into your environment.</p>
<p>I&#8217;m not going to plug anything that I use personally in this but if you are interested in landscape to what I use go ahead and comment or better yet, start up a thread in the <a href="http://forum.lessthandot.com/viewforum.php?f=22">DB related forums</a>.</p>
]]></content:encoded>
			<wfw:commentRss>/index.php/datamgmt/dbadmin/death-by-a-thousand-tools/feed/</wfw:commentRss>
		<slash:comments>2</slash:comments>
		</item>
	</channel>
</rss>
