<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	>
<channel>
	<title>Comments on: How to Delete Large amounts of data in a Batch.</title>
	<atom:link href="/index.php/datamgmt/datadesign/how-to-delete-large-amounts/feed/" rel="self" type="application/rss+xml" />
	<link>/index.php/datamgmt/datadesign/how-to-delete-large-amounts/</link>
	<description>A Technical Community for IT Professionals</description>
	<lastBuildDate>Tue, 26 Feb 2019 12:40:14 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.6.1</generator>
	<item>
		<title>By: ptheriault</title>
		<link>/index.php/datamgmt/datadesign/how-to-delete-large-amounts/#comment-3526</link>
		<dc:creator><![CDATA[ptheriault]]></dc:creator>
		<pubDate>Fri, 21 Jan 2011 10:40:09 +0000</pubDate>
		<guid isPermaLink="false">/index.php/2011/01/how-to-delete-large-amounts/#comment-3526</guid>
		<description><![CDATA[Wow, I touched off a firestorm here.   I know the code isn&#039;t 100% correct, I was really only trying to show the GO [int] statment.  It was something I only just learned and I thought I would share it. WGW, your approach doesn&#039;t always work if the table needs to accessed by other processes in between your batch deletes.]]></description>
		<content:encoded><![CDATA[<p>Wow, I touched off a firestorm here.   I know the code isn&#8217;t 100% correct, I was really only trying to show the GO [int] statment.  It was something I only just learned and I thought I would share it. WGW, your approach doesn&#8217;t always work if the table needs to accessed by other processes in between your batch deletes.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Erik</title>
		<link>/index.php/datamgmt/datadesign/how-to-delete-large-amounts/#comment-3525</link>
		<dc:creator><![CDATA[Erik]]></dc:creator>
		<pubDate>Thu, 20 Jan 2011 20:51:05 +0000</pubDate>
		<guid isPermaLink="false">/index.php/2011/01/how-to-delete-large-amounts/#comment-3525</guid>
		<description><![CDATA[Log space is definitely a hidden gotcha when doing huge deletes (truncates, too).&lt;br /&gt;
&lt;br /&gt;
For some colossally-sized delete operation, if you don&#039;t want your log file to grow really large, batched deletes with interspersed log backups are the only way to prevent this.&lt;br /&gt;
&lt;br /&gt;
If your database is in simple recovery mode, you don&#039;t even need the log backups, but you still need the batched deletes to keep the total log size small. &lt;br /&gt;
&lt;br /&gt;
Using batched deletes is going to be faster, too. But truncate is fastest... but locks the table for the entire operation which also may not be right.&lt;br /&gt;
&lt;br /&gt;
I agree with Denis to use WHILE @@Rowcount &gt; 0 DELETE ...]]></description>
		<content:encoded><![CDATA[<p>Log space is definitely a hidden gotcha when doing huge deletes (truncates, too).</p>
<p>For some colossally-sized delete operation, if you don&#8217;t want your log file to grow really large, batched deletes with interspersed log backups are the only way to prevent this.</p>
<p>If your database is in simple recovery mode, you don&#8217;t even need the log backups, but you still need the batched deletes to keep the total log size small. </p>
<p>Using batched deletes is going to be faster, too. But truncate is fastest&#8230; but locks the table for the entire operation which also may not be right.</p>
<p>I agree with Denis to use WHILE @@Rowcount > 0 DELETE &#8230;</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: SQLDenis</title>
		<link>/index.php/datamgmt/datadesign/how-to-delete-large-amounts/#comment-3524</link>
		<dc:creator><![CDATA[SQLDenis]]></dc:creator>
		<pubDate>Thu, 20 Jan 2011 15:48:17 +0000</pubDate>
		<guid isPermaLink="false">/index.php/2011/01/how-to-delete-large-amounts/#comment-3524</guid>
		<description><![CDATA[I usually do it this way&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;
That way it only loops until the table is empty&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;
I had to run something like it against a big table...just be careful with enough log space...sometime it is faster to insert into another table what you want to keep, truncate this table and then insert the rows you want..if what you want to keep is much smaller&lt;br /&gt;
&lt;br /&gt;
&lt;codeblock lang=&quot;tsql&quot; line=&quot;1&quot;&gt;CREATE TABLE #test (id INT, somevalue VARCHAR(200) )&lt;br /&gt;
GO&lt;br /&gt;
&lt;br /&gt;
--INSERT 2506 rows&lt;br /&gt;
INSERT #test&lt;br /&gt;
SELECT number, NEWID()&lt;br /&gt;
FROM master..spt_values&lt;br /&gt;
&lt;br /&gt;
WHILE @@rowcount &gt; 0&lt;br /&gt;
BEGIN&lt;br /&gt;
     DELETE TOP (500) #test&lt;br /&gt;
END&lt;br /&gt;
&lt;br /&gt;
&lt;/codeblock&gt;&lt;br /&gt;
---------------------&lt;br /&gt;
(500 row(s) affected)&lt;br /&gt;
(500 row(s) affected)&lt;br /&gt;
(500 row(s) affected)&lt;br /&gt;
(500 row(s) affected)&lt;br /&gt;
(500 row(s) affected)&lt;br /&gt;
(6 row(s) affected)&lt;br /&gt;
(0 row(s) affected)]]></description>
		<content:encoded><![CDATA[<p>I usually do it this way</p>
<p>
That way it only loops until the table is empty</p>
<p>
I had to run something like it against a big table&#8230;just be careful with enough log space&#8230;sometime it is faster to insert into another table what you want to keep, truncate this table and then insert the rows you want..if what you want to keep is much smaller</p>
<p><codeblock lang="tsql" line="1">CREATE TABLE #test (id INT, somevalue VARCHAR(200) )<br />
GO</p>
<p>&#8211;INSERT 2506 rows<br />
INSERT #test<br />
SELECT number, NEWID()<br />
FROM master..spt_values</p>
<p>WHILE @@rowcount > 0<br />
BEGIN<br />
     DELETE TOP (500) #test<br />
END</p>
<p></codeblock><br />
&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;<br />
(500 row(s) affected)<br />
(500 row(s) affected)<br />
(500 row(s) affected)<br />
(500 row(s) affected)<br />
(500 row(s) affected)<br />
(6 row(s) affected)<br />
(0 row(s) affected)</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: wqw</title>
		<link>/index.php/datamgmt/datadesign/how-to-delete-large-amounts/#comment-3523</link>
		<dc:creator><![CDATA[wqw]]></dc:creator>
		<pubDate>Thu, 20 Jan 2011 15:39:32 +0000</pubDate>
		<guid isPermaLink="false">/index.php/2011/01/how-to-delete-large-amounts/#comment-3523</guid>
		<description><![CDATA[Or you could do it the other way&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;
&lt;codeblock lang=&quot;tsql&quot; line=&quot;1&quot;&gt;SELECT *&lt;br /&gt;
INTO dbo.tmp_log&lt;br /&gt;
FROM dbo.log&lt;br /&gt;
WHERE timestamp &gt;= @Timestamp&lt;br /&gt;
&lt;br /&gt;
DROP TABLE dbo.log&lt;br /&gt;
&lt;br /&gt;
exec sp_rename &#039;dbo.tmp_log&#039;, &#039;dbo.log&#039;&lt;/codeblock&gt;&lt;br /&gt;
&lt;br /&gt;
&lt;br /&gt;
... if there are no FKs to log table. You&#039;ll have to reindex it too.]]></description>
		<content:encoded><![CDATA[<p>Or you could do it the other way</p>
<p>
<codeblock lang="tsql" line="1">SELECT *<br />
INTO dbo.tmp_log<br />
FROM dbo.log<br />
WHERE timestamp >= @Timestamp</p>
<p>DROP TABLE dbo.log</p>
<p>exec sp_rename &#8216;dbo.tmp_log&#8217;, &#8216;dbo.log&#8217;</codeblock></p>
<p>
&#8230; if there are no FKs to log table. You&#8217;ll have to reindex it too.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Naomi Nosonovsky</title>
		<link>/index.php/datamgmt/datadesign/how-to-delete-large-amounts/#comment-3522</link>
		<dc:creator><![CDATA[Naomi Nosonovsky]]></dc:creator>
		<pubDate>Thu, 20 Jan 2011 15:15:24 +0000</pubDate>
		<guid isPermaLink="false">/index.php/2011/01/how-to-delete-large-amounts/#comment-3522</guid>
		<description><![CDATA[If you put the above in a loop with &lt;br /&gt;
if @@ROWCOUNT = 0&lt;br /&gt;
   BREAK&lt;br /&gt;
&lt;br /&gt;
can you still use this trick?]]></description>
		<content:encoded><![CDATA[<p>If you put the above in a loop with <br />
if @@ROWCOUNT = 0<br />
   BREAK</p>
<p>can you still use this trick?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: AaronBertrand</title>
		<link>/index.php/datamgmt/datadesign/how-to-delete-large-amounts/#comment-3521</link>
		<dc:creator><![CDATA[AaronBertrand]]></dc:creator>
		<pubDate>Thu, 20 Jan 2011 12:59:40 +0000</pubDate>
		<guid isPermaLink="false">/index.php/2011/01/how-to-delete-large-amounts/#comment-3521</guid>
		<description><![CDATA[Paul, this is good for something you really want to do 500 times. With a DELETE, what if there are only 100,000 rows to delete?  You&#039;re going to execute the query 490 times for no reason... and if a scan is chosen to locate the rows to delete, this could be a pretty expensive no-op.  I would rather do something like this (tailoring the TOP and % values depending on the size of the table and my tolerance for log pain):&lt;br /&gt;
&lt;a href=&quot; http://twitpic.com/3rql7o&quot;&gt;&lt;br /&gt;
http://twitpic.com/3rql7o&lt;/a&gt;&lt;br /&gt;
&lt;br /&gt;
It&#039;s messier code, I admit, and I think the [GO int] is a fantastic and little-known gem, but I think a filtered delete is not a very practical use case.&lt;br /&gt;
&lt;br /&gt;
Also, just as an aside, you didn&#039;t give @Timestamp a value.  So actually you are going to execute this delete 500 times and never affect a single row...]]></description>
		<content:encoded><![CDATA[<p>Paul, this is good for something you really want to do 500 times. With a DELETE, what if there are only 100,000 rows to delete?  You&#8217;re going to execute the query 490 times for no reason&#8230; and if a scan is chosen to locate the rows to delete, this could be a pretty expensive no-op.  I would rather do something like this (tailoring the TOP and % values depending on the size of the table and my tolerance for log pain):<br />
<a href=" http://twitpic.com/3rql7o"><br />
</a><a href="http://twitpic.com/3rql7o" rel="nofollow">http://twitpic.com/3rql7o</a></p>
<p>It&#8217;s messier code, I admit, and I think the [GO int] is a fantastic and little-known gem, but I think a filtered delete is not a very practical use case.</p>
<p>Also, just as an aside, you didn&#8217;t give @Timestamp a value.  So actually you are going to execute this delete 500 times and never affect a single row&#8230;</p>
]]></content:encoded>
	</item>
</channel>
</rss>
